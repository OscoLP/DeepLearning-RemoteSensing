{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_1D_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLraymt+PeFyN0d5lMlVTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscoLP/DeepLearning-RemoteSensing/blob/main/CNN_1D_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5PQEZLKPt07"
      },
      "source": [
        "***Mount GoogleCollabs drive***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnf8GnqKZUYY"
      },
      "source": [
        "from google.colab import drive \r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSF3TwqLP1VS"
      },
      "source": [
        "***Read the .csv file***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_mshP8pZ7Z1"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "train = pd.read_csv('gdrive/My Drive/Colab Notebooks/Train.csv')\r\n",
        "x_train = train.iloc[:, 0:-1].values\r\n",
        "y_train = train.iloc[:, -1].values\r\n",
        "\r\n",
        "test = pd.read_csv('gdrive/My Drive/Colab Notebooks/Test.csv')\r\n",
        "x_test = test.iloc[:, 0:-1].values\r\n",
        "y_test = test.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7VzYDxqP4I-"
      },
      "source": [
        "***Normalize the data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd4K5IMkfa09"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\r\n",
        "x_train = sc.fit_transform(x_train)\r\n",
        "x_test = sc.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC6BnzpHP6n2"
      },
      "source": [
        "***Reduce dimensionality***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJmNvBeW744R"
      },
      "source": [
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "pca = PCA(n_components=100)\r\n",
        "x_train = pca.fit_transform(x_train)\r\n",
        "x_test = pca.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V471bMGQCW3"
      },
      "source": [
        "***Reshape data for a 1D-CNN dimension***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AsM6UAEfeQd"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1, 1).astype('float32')\r\n",
        "x_test = x_test.reshape(x_test.shape[0], -1, 1).astype('float32')\r\n",
        "\r\n",
        "y_train = y_train.reshape(y_train.shape[0], 1, 1).astype('float32')\r\n",
        "y_test = y_test.reshape(y_test.shape[0], 1, 1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nck8Gf8QNBj"
      },
      "source": [
        "***Import the model (keras)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49O_4fCCY4Rm"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Convolution1D\r\n",
        "from keras.layers import MaxPooling1D\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65WSO2FKQOMT"
      },
      "source": [
        "***Define the model structure***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJGGGmPzZEf0"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Convolution1D(128, 3, 3, input_shape=(x_train.shape[1:]), activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(Convolution1D(128, 3, 3, activation='relu'))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Convolution1D(32, 3, 3, activation='relu'))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Convolution1D(32, 3, 3, activation='relu'))\r\n",
        "model.add(MaxPooling1D(pool_size=(1)))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Dense(32, activation='relu'))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdZK-YQMQQSi"
      },
      "source": [
        "***Compile and train the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8oRLpkhZIMY"
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "history = model.fit(x_train, y_train, epochs = 200, batch_size = 32, verbose = 1, shufle = True, validation_split= 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLUKJsbEQSOg"
      },
      "source": [
        "***Visualize the training performance***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2Vixr3ZL6a"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(history.history['loss'], label='Loss (training data)')\r\n",
        "plt.plot(history.history['val_loss'], label='Loss (validation data)')\r\n",
        "plt.title('Historic - Loss')\r\n",
        "plt.ylabel('Loss value')\r\n",
        "plt.xlabel('No. epoch')\r\n",
        "plt.legend(loc=\"upper right\")\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.plot(history.history['accuracy'], label='Accuracy (training data)')\r\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\r\n",
        "plt.title('Historic - Acc')\r\n",
        "plt.ylabel('Acc value')\r\n",
        "plt.xlabel('No. epoch')\r\n",
        "plt.legend(loc=\"best\")\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTiAgkepQYpT"
      },
      "source": [
        "***Calculate the model accuracy***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wDYjM6HfqgN"
      },
      "source": [
        "_, accuracy = model.evaluate(x_test, y_test)\r\n",
        "print('Accuracy: %.2f' % (accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmOPITV5Qb76"
      },
      "source": [
        "***Print the model predictions***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG797-R2fq-i"
      },
      "source": [
        "y_pred = model.predict(x_test)\r\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G3M6q-aQjfu"
      },
      "source": [
        "***Print the model rounded predictions***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi6UYVjYQlEG"
      },
      "source": [
        "import numpy as np\r\n",
        "import itertools\r\n",
        "\r\n",
        "y_rounded_predictions = np.argmax(y_pred, axis=-1)\r\n",
        "y_initial_labels = test.iloc[:, -1].values\r\n",
        "\r\n",
        "print(y_rounded_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx9xaud_QrKt"
      },
      "source": [
        "***Visualize the confusion matrix***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9i5F1Ehfvu4"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "y_rounded_predictions = np.argmax(y_pred, axis=-1)\r\n",
        "y_initial_labels = test.iloc[:, -1].values\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "cm = confusion_matrix(y_initial_labels, y_rounded_predictions)\r\n",
        "def plot_confusion_matrix(cm, classes,\r\n",
        "                        normalize=False,\r\n",
        "                        title='Confusion Matrix',\r\n",
        "                        cmap=plt.cm.Blues):\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "        print(\"Normalized confusion matrix\")\r\n",
        "    else:\r\n",
        "        print('Confusion matrix, without normalization')\r\n",
        "\r\n",
        "    print(cm)\r\n",
        "\r\n",
        "    thresh = cm.max() / 3.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, cm[i, j],\r\n",
        "            horizontalalignment=\"center\",\r\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')\r\n",
        "    cm_plot_labels = ['0','1']\r\n",
        "\r\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}